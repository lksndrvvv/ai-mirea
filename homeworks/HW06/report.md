# HW06 — Trees and Ensembles

## 1. Dataset

В работе использован датасет **S06-hw-dataset-01.csv**.

Задача — бинарная классификация.
Таргет — столбец `target` (значения 0 и 1).

Датасет содержит числовые признаки (`num01`–`num24`),
несколько категориальных-подобных признаков (`cat_contract`, `cat_region`, `cat_payment`),
а также признак `tenure_months`.

Столбец `id` использовался только как идентификатор и не включался в признаки.

## 2. Train / Test split

Данные были разделены на обучающую и тестовую выборки
в пропорции **80% / 20%**.

Параметры разбиения:
- `test_size = 0.2`
- `random_state = 42`
- `stratify = y`

Фиксация `random_state` обеспечивает воспроизводимость результатов.
Использование стратификации позволяет сохранить распределение классов
в train и test выборках.

## 3. Baseline models

В качестве baseline-моделей были использованы:

1. **DummyClassifier** (strategy = `most_frequent`) — простейшая модель,
   служащая минимальным ориентиром качества.

2. **LogisticRegression** в составе Pipeline со StandardScaler —
   линейная модель, используемая как более сильный baseline.

Обе модели обучались на train выборке и оценивались на test.

## 4. Models of week 6

В рамках задания были обучены и сравнены следующие модели недели 6:

- **DecisionTreeClassifier** с контролем сложности
  (использовались параметры `max_depth` и `min_samples_leaf`);
- **RandomForestClassifier**;
- **GradientBoostingClassifier**.

Для всех моделей подбор гиперпараметров выполнялся
**только на train выборке** с использованием кросс-валидации.

## 5. Evaluation metrics

Для оценки качества моделей использовались следующие метрики:

- accuracy;
- f1-score;
- ROC-AUC.

Так как задача является бинарной классификацией,
ROC-AUC был выбран в качестве основного критерия сравнения моделей,
поскольку он менее чувствителен к дисбалансу классов.

## 6. Results on test set

Результаты моделей на test выборке представлены в таблице ниже.

| Model                | Accuracy | F1     | ROC-AUC |
|----------------------|----------|--------|---------|
| DummyClassifier      | 0.677    | 0.000  | 0.500   |
| LogisticRegression   | 0.828    | 0.708  | 0.875   |
| DecisionTree         | 0.869    | 0.794  | 0.910   |
| RandomForest         | 0.929    | 0.885  | 0.967   |
| GradientBoosting     | 0.916    | 0.863  | 0.961   |

Все значения рассчитаны на test выборке,
которая не использовалась при подборе гиперпараметров.

## 7. Best model

Лучшей моделью был выбран **RandomForestClassifier**,
так как он показал наибольшее значение **ROC-AUC = 0.967**
на test выборке.

Именно эта модель использовалась для дальнейшей интерпретации.

## 8. Diagnostic plots

Для лучшей модели были построены и сохранены диагностические графики:

- ROC-кривая (`roc_RandomForest.png`);
- confusion matrix (`cm_RandomForest.png`).

Также был сохранён график permutation importance
(`importance_RandomForest.png`).

Все графики находятся в папке `artifacts/figures/`.

## 9. Model interpretation

Для интерпретации лучшей модели была рассчитана permutation importance.

Были рассмотрены топ-10 признаков по величине importance.
Наиболее важными оказались признаки `num19`, `num18`, `num07`, `num04` и `num20`.

Эти признаки вносят наибольший вклад в качество модели,
так как при их перестановке значение ROC-AUC снижается сильнее всего.
Полученные результаты выглядят согласованными с тем,
что ансамблевые методы хорошо улавливают нелинейные зависимости
между числовыми признаками.

## 10. Conclusions

В ходе работы были сравнены baseline-модели и ансамблевые методы.
Ансамбли (RandomForest и GradientBoosting) существенно превзошли baseline
по всем основным метрикам качества.

Использование честного ML-эксперимента с фиксированным train/test split
и кросс-валидацией позволило корректно выбрать лучшую модель
и получить воспроизводимые результаты.
