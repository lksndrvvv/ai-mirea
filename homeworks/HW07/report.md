# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Я выбрала 3 датасета из 4.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 10000 строк, 9 столбцов (1 sample_id + 8 признаков)
- Признаки: все признаки числовые
- Пропуски: пропусков нет
- "Подлости" датасета: признаки находятся в разных шкалах, без масштабирования distance-based методы работают плохо

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: около 50 строк, 4 столбца (1 sample_id + 3 признака)
- Признаки: все признаки числовые
- Пропуски: пропусков нет
- "Подлости" датасета: нелинейная структура данных, выбросы и шумовой признак `z_noise`

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: 10000 строк, 33 столбца (1 sample_id + признаки)
- Признаки: числовые и категориальные (`cat_a`, `cat_b`)
- Пропуски: есть пропуски в числовых признаках
- "Подлости" датасета: высокая размерность, пропуски и категориальные признаки, требуется аккуратный препроцессинг

## 2. Protocol

Я использовала единый и честный unsupervised-протокол.

**Препроцессинг:**
- Dataset 01 и Dataset 02: StandardScaler для всех числовых признаков.
- Dataset 04:
  - числовые признаки: SimpleImputer(strategy="mean") + StandardScaler;
  - категориальные признаки: SimpleImputer(strategy="most_frequent") + OneHotEncoder(handle_unknown="ignore").
PCA использовался только для визуализации (2D), не для обучения моделей.

**Поиск гиперпараметров:**
- KMeans: подбор числа кластеров `k` в диапазоне от 2 до 20, фиксировались `random_state=42` и `n_init=10`.
- DBSCAN: подбор `eps` при фиксированном `min_samples=5`.
- AgglomerativeClustering: подбор `k` и сравнение linkage (`ward`, `average`).
Лучшее решение выбиралось по метрике silhouette (выше — лучше).

**Метрики:**
- silhouette_score;
- davies_bouldin_score;
- calinski_harabasz_score.
Для DBSCAN дополнительно считалась доля шума (label = -1), метрики считались только на non-noise точках.

**Визуализация:**
- Для каждого датасета построен PCA(2D) scatter для лучшего решения.


## 3. Models

### Dataset A (S07-hw-dataset-01)

- KMeans: подбор `k`, фиксированы `random_state=42`, `n_init=10`
- DBSCAN: подбор `eps`, `min_samples=5`

### Dataset B (S07-hw-dataset-02)

- KMeans: подбор `k`, фиксированы `random_state=42`, `n_init=10`
- DBSCAN: подбор `eps`, `min_samples=5`, анализ доли шума

### Dataset C (S07-hw-dataset-04)

- KMeans: подбор `k`, фиксированы `random_state=42`, `n_init=10`
- AgglomerativeClustering: подбор `k`, сравнение linkage (`ward`, `average`)


## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k = 2
- Метрики:
  - silhouette = 0.522
  - Davies-Bouldin = 0.685
  - Calinski-Harabasz = 11786.95
- DBSCAN: доля шума = 0.0
- Комментарий: после масштабирования KMeans дал более чёткую и устойчивую структуру кластеров по всем метрикам

### 4.2 Dataset B

- Лучший метод и параметры: KMeans, k = 2
- Метрики:
  - silhouette = 0.307
  - Davies-Bouldin = 1.323
  - Calinski-Harabasz = 3573.39
- DBSCAN: доля шума ≈ 6.2%
- Комментарий: несмотря на наличие шума и нелинейной структуры, по silhouette KMeans оказался лучше, поэтому он был выбран

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, k = 5
- Метрики:
  - silhouette = 0.448
  - Davies-Bouldin = 0.976
  - Calinski-Harabasz = 5103.10
- Комментарий: KMeans и Agglomerative дали одинаковые метрики, поэтому был выбран более простой метод KMeans


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans чувствителен к масштабу признаков, без масштабирования результаты были бы хуже.
- DBSCAN хорошо выделяет шум, но чувствителен к выбору `eps`.
- На небольших и шумных датасетах выбор метрики сильно влияет на итоговое решение.
- Пропуски и категориальные признаки требуют обязательного препроцессинга, иначе кластеризация некорректна.

### 5.2 Устойчивость (обязательно для одного датасета)

Проверка устойчивости была выполнена для Dataset A.
Я запустила KMeans 5 раз с разными `random_state` и сравнила разбиения с помощью ARI.

Результат:
- средний ARI = 1.0
- минимальный ARI = 1.0
- максимальный ARI = 1.0

Вывод: кластеризация полностью устойчива, разбиения совпадают при разных seed.

### 5.3 Интерпретация кластеров

Кластеры интерпретировались через различия в значениях признаков.
В каждом датасете кластеры отражают группы объектов с похожими значениями числовых признаков.
В Dataset 04 категории также вносят вклад через one-hot кодирование.
В целом кластеры выглядят осмысленными с точки зрения структуры данных.


## 6. Conclusion

- Я научилась применять разные методы кластеризации в зависимости от структуры данных.
- Масштабирование является обязательным шагом для distance-based алгоритмов.
- Внутренние метрики помогают сравнивать решения без истинных меток, но могут давать разные сигналы.
- DBSCAN полезен для поиска шума, но чувствителен к параметрам.
- KMeans прост в использовании и показал стабильные результаты на нескольких датасетах.
- Проверка устойчивости важна для понимания надёжности кластеризации.
- Корректный unsupervised-протокол требует аккуратного препроцессинга и честного сравнения методов.
